{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project: **Vehicle Detection and Tracking** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Anaconda\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#importing some useful packages\n",
    "from glob import glob\n",
    "import random\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, grid_search\n",
    "import pickle\n",
    "\n",
    "from helper_functions import get_hog_features, bin_spatial, extract_features, slide_window, convert_color\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Classifier Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_params = pickle.load(open(\"classifier_params.pkl\", \"rb\"))\n",
    "svc = classifier_params['svc']\n",
    "X_scaler = classifier_params['X_scaler']\n",
    "orient = classifier_params['orient']\n",
    "pix_per_cell = classifier_params['pix_per_cell']\n",
    "cell_per_block = classifier_params['cell_per_block']\n",
    "spatial_size = classifier_params['spatial_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Cars In An Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size):\n",
    "    \n",
    "    #draw_img = np.copy(img)\n",
    "    #img = img.astype(np.float32)/255\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, conv='RGB2GRAY')\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        \n",
    "    list_of_boxes = []\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG\n",
    "            hog_features = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(np.hstack((spatial_features, hog_features)).reshape(1, -1))    \n",
    "            #test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))    \n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                pt1 = (xbox_left, ytop_draw+ystart)\n",
    "                pt2 = (xbox_left+win_draw,ytop_draw+win_draw+ystart)\n",
    "                #print(pt1, pt2)\n",
    "                #cv2.rectangle(draw_img,pt1,pt2,(0,0,255),6) \n",
    "                list_of_boxes.append((pt1,pt2))\n",
    "                \n",
    "    #return draw_img, list_of_boxes\n",
    "    return list_of_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Sized Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_image = glob('test_images/test3*.jpg')\n",
    "\n",
    "img = mpimg.imread(test_image)\n",
    "\n",
    "draw_img = np.copy(img)\n",
    "img = img.astype(np.float32)/255\n",
    "\n",
    "for scale in scales:\n",
    "    if 0 != len(list_of_boxes):\n",
    "        for box in list_of_boxes:\n",
    "            pt1 = box[0]\n",
    "            pt2 = box[1]\n",
    "            #print(pt1, pt2, type(pt1), type(pt2))\n",
    "            cv2.rectangle(draw_img,pt1,pt2,(0,0,255),6) \n",
    "\n",
    "plt.figure(image_num)\n",
    "plt.imshow(draw_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\skimage\\feature\\_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    }
   ],
   "source": [
    "test_images = glob('test_images/*.jpg')\n",
    "\n",
    "ystart = 400\n",
    "ystop = 650\n",
    "scales = [1.3, 1.5, 2, 2.5]\n",
    "\n",
    "image_num = 0\n",
    "for image_path in test_images:\n",
    "    image_num += 1\n",
    "    img = mpimg.imread(image_path)\n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    img = img.astype(np.float32)/255\n",
    "\n",
    "    for scale in scales:\n",
    "        \n",
    "        if scale >= 2:\n",
    "            y_start_new = ystart\n",
    "            ystop_new = ystart + (ystop - ystart)/2\n",
    "        else:            \n",
    "            y_start_new = ystart + (ystop - ystart)/2\n",
    "            ystop_new = ystop\n",
    "            \n",
    "        #out_img, list_of_boxes = find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size)\n",
    "        list_of_boxes = find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size)\n",
    "        \n",
    "        if 0 != len(list_of_boxes):\n",
    "            for box in list_of_boxes:\n",
    "                pt1 = box[0]\n",
    "                pt2 = box[1]\n",
    "                #print(pt1, pt2, type(pt1), type(pt2))\n",
    "                cv2.rectangle(draw_img,pt1,pt2,(0,0,255),6) \n",
    "    \n",
    "    plt.figure(image_num, figsize = (15, 10))\n",
    "    plt.imshow(draw_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data Into Training And Testing Set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data Into Training And Testing Set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test pipeline on an image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "frame_number = 0\n",
    "Left_Lane = Line()\n",
    "Right_Lane = Line()\n",
    "image = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "#image = mpimg.imread('test_images/test6.jpg')\n",
    "#process_image(image)\n",
    "#process_image(image)\n",
    "#process_image(image)\n",
    "#process_image(image)\n",
    "#process_image(image)\n",
    "#process_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test pipeline on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_output = 'project_video_output.mp4'\n",
    "#video_output = 'challenge_video_output.mp4'\n",
    "#video_output = 'harder_challenge_video_output.mp4'\n",
    "\n",
    "\n",
    "frame_number = 0\n",
    "Left_Lane = Line()\n",
    "Right_Lane = Line()\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "#clip1 = VideoFileClip(\"project_video.mp4\").subclip(0,1)\n",
    "#clip1 = VideoFileClip(\"project_video.mp4\").subclip(26,27)\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "#clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "#clip1 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "video_frame = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time video_frame.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the video inline, or if you prefer find the video in your filesystem (should be in the same directory) and play it in your video player of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
